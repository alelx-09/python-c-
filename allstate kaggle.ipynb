{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "from PIL import Image \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a refrence to all the floders including root\n",
    "rootdir=\"Desktop/statefarm1/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 folders with the data \n",
      "\n",
      "the first folder contains 2489 pictures\n",
      "the second folder contains 2267 pictures\n",
      "the third folder contains 2317 pictures\n",
      "the fourth folder contains 2346 pictures\n",
      "the fifth folder contains 2326 pictures\n",
      "the sixth folder contains 2312 pictures\n",
      "the seventh folder contains 2325 pictures\n",
      "the eight folder contains 2002 pictures\n",
      "the nineth folder contains 1911 pictures\n",
      "the tenthfolder contains 2129 pictures\n"
     ]
    }
   ],
   "source": [
    "foldrs =(len(os.listdir(rootdir)))\n",
    "print(str(foldrs) + \" folders with the data \\n\")\n",
    "\n",
    "f0= len(os.listdir(\"Desktop/statefarm1/train/c0/\"))\n",
    "f1= len(os.listdir(\"Desktop/statefarm1/train/c1/\"))\n",
    "f2= len(os.listdir(\"Desktop/statefarm1/train/c2/\"))\n",
    "f3= len(os.listdir(\"Desktop/statefarm1/train/c3\"))\n",
    "f4= len(os.listdir(\"Desktop/statefarm1/train/c4/\"))\n",
    "f5= len(os.listdir(\"Desktop/statefarm1/train/c5/\"))\n",
    "f6= len(os.listdir(\"Desktop/statefarm1/train/c6/\"))\n",
    "f7= len(os.listdir(\"Desktop/statefarm1/train/c7/\"))\n",
    "f8= len(os.listdir(\"Desktop/statefarm1/train/c8/\"))\n",
    "f9= len(os.listdir(\"Desktop/statefarm1/train/c9/\"))\n",
    "\n",
    "print(\"the first folder contains \"+ str(f0) +\" pictures\")\n",
    "print(\"the second folder contains \"+ str(f1) +\" pictures\")\n",
    "print(\"the third folder contains \"+ str(f2) +\" pictures\")\n",
    "print(\"the fourth folder contains \"+ str(f3) +\" pictures\")\n",
    "print(\"the fifth folder contains \"+ str(f4) +\" pictures\")\n",
    "print(\"the sixth folder contains \"+ str(f5) +\" pictures\")\n",
    "print(\"the seventh folder contains \"+ str(f6) +\" pictures\")\n",
    "print(\"the eight folder contains \"+ str(f7) +\" pictures\")\n",
    "print(\"the nineth folder contains \"+ str(f8) +\" pictures\")\n",
    "print(\"the tenthfolder contains \"+ str(f9) +\" pictures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def create_new_dir():\n",
    "    \n",
    "    if not os.path.exists('Desktop/trainstate'):\n",
    "        os.mkdir('Desktop/trainstate')\n",
    "        \n",
    "create_new_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "src = 'Desktop/statefarm1/train/'\n",
    "dest = 'Desktop/trainstate'\n",
    "\n",
    "for path, subdirs, files in os.walk(src):\n",
    "    for name in files:\n",
    "        filename = os.path.join(path, name)\n",
    "        shutil.copy(filename, dest)\n",
    "#in pictures folder sort by date and decending!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = 'Desktop/trainstate/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size=150\n",
    "chan = 3\n",
    "num_pics = len(os.listdir(train_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22424"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, im in enumerate(os.listdir(train_dir)):\n",
    "    \n",
    "    data= np.ndarray([num_pics, size, size ,chan])\n",
    "    img = Image.open(train_dir+ im)\n",
    "    im_resize= img.resize((size,size),Image.ANTIALIAS)\n",
    "    im_array= np.array(im_resize)\n",
    "    im_normal = im_array-(255.0/2)/255.0\n",
    "    data[i,:,:,:]= im_normal.reshape(-1,size,size,chan)\n",
    "    X_train= data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 22424 preproccesd pictures\n"
     ]
    }
   ],
   "source": [
    "l=len(X_train)\n",
    "print(\"there are \" + str(l) + \" preproccesd pictures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "la= []\n",
    "for pic in enumerate(os.listdir(\"Desktop/statefarm1/train/c0/\")):\n",
    "    la.append(9)\n",
    "for pic in enumerate( os.listdir(\"Desktop/statefarm1/train/c1/\")):\n",
    "    la.append(8)\n",
    "for pic in enumerate( os.listdir(\"Desktop/statefarm1/train/c2/\")):\n",
    "    la.append(7)\n",
    "for pic in enumerate(os.listdir(\"Desktop/statefarm1/train/c3/\")):\n",
    "    la.append(6)\n",
    "for pic in enumerate(os.listdir(\"Desktop/statefarm1/train/c4/\")):\n",
    "    la.append(5)\n",
    "for pic in enumerate(os.listdir(\"Desktop/statefarm1/train/c5/\")):\n",
    "    la.append(4)\n",
    "for pic in enumerate(os.listdir(\"Desktop/statefarm1/train/c6/\")):\n",
    "    la.append(3)\n",
    "for pic in enumerate (os.listdir(\"Desktop/statefarm1/train/c7/\")):\n",
    "    la.append(2)\n",
    "for pic in enumerate(os.listdir(\"Desktop/statefarm1/train/c8/\")):\n",
    "    la.append(1)\n",
    "for pic in enumerate(os.listdir(\"Desktop/statefarm1/train/c9/\")):\n",
    "    la.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22424"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAFJCAYAAAB3vj+vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIAIPAICBCDwAAAb6H2qkFdY9Xm4PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28e90676b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(la)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(150, 150,..., activation=\"relu\", padding=\"same\")`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  if sys.path[0] == '':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  del sys.path[0]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chan =3\n",
    "optimizer = RMSprop(lr=1e-4)\n",
    "objective = 'binary_crossentropy'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same', input_shape=(size,size,chan), activation='relu'))\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16818 samples, validate on 5606 samples\n",
      "Epoch 1/2\n",
      "16818/16818 [==============================] - 2632s - loss: 0.4059 - acc: 0.0000e+00 - val_loss: 0.6523 - val_acc: 0.3411\n",
      "Epoch 2/2\n",
      "16818/16818 [==============================] - 2663s - loss: -0.1586 - acc: 0.0000e+00 - val_loss: 0.6146 - val_acc: 0.3411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28e91252cc0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch = 2\n",
    "batch_size = 16\n",
    "model.fit(X_train, la, batch_size=batch_size, nb_epoch=nb_epoch, validation_split=0.25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('Desktop/drink.png')\n",
    "img = cv2.resize(img,(size,size))\n",
    "img = np.reshape(img,[1,size,size,chan])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(img, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.38995594]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for more accurate results lets try to add some controled noise to our data\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        \"Desktop/statefarm1/train/\",  # this is the target directory\n",
    "        target_size=(size, size),  # all images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., steps_per_epoch=125, epochs=20)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 359s - loss: -54.4765 - acc: 0.1008   \n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 358s - loss: -53.3367 - acc: 0.0876   \n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 364s - loss: -51.7425 - acc: 0.1028   \n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 354s - loss: -53.6748 - acc: 0.0940   \n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 351s - loss: -52.2262 - acc: 0.1100   \n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 345s - loss: -52.9096 - acc: 0.0996   \n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 348s - loss: -53.5322 - acc: 0.1020   \n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 348s - loss: -51.4616 - acc: 0.1148   \n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 355s - loss: -53.8763 - acc: 0.0992   \n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 343s - loss: -54.0061 - acc: 0.0988   \n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 344s - loss: -52.4757 - acc: 0.0980   \n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 340s - loss: -54.1467 - acc: 0.0984   \n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 347s - loss: -52.6726 - acc: 0.1008   \n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 351s - loss: -53.8138 - acc: 0.1084   \n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 355s - loss: -53.4193 - acc: 0.1032   \n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 357s - loss: -52.6792 - acc: 0.1032   \n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 346s - loss: -52.1183 - acc: 0.0960   \n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 338s - loss: -52.3348 - acc: 0.1044   \n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 334s - loss: -53.1322 - acc: 0.1000   \n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 333s - loss: -52.9606 - acc: 0.0984   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28e92464dd8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "model.fit_generator(\n",
    "        train_generator,steps_per_epoch=2000 // batch_size,\n",
    " nb_epoch=20)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('alex_modelbigg1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('alex_modelbigg1.h5')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('Desktop/drink.png')\n",
    "img = cv2.resize(img,(size,size))\n",
    "img = np.reshape(img,[1,size,size,chan])\n",
    "\n",
    "classes = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
